"""
Demonstration script showing the enhanced air quality analysis system
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def analyze_air_quality_system():
    """
    Analyze and display the comprehensive air quality system we've built
    """
    print("ğŸŒ SULAIMANI AIR QUALITY ANALYSIS SYSTEM")
    print("=" * 55)
    
    # Check data availability
    data_files = {
        'Combined Grid Data': 'air_quality_combined_grid.csv',
        'Composite AQI': 'composite_air_quality_index.csv',
        'NOâ‚‚ Interpolated': 'air_quality_no2_interpolated.csv',
        'SOâ‚‚ Interpolated': 'air_quality_so2_interpolated.csv',
        'CO Interpolated': 'air_quality_co_interpolated.csv',
        'Oâ‚ƒ Interpolated': 'air_quality_o3_interpolated.csv',
        'HCHO Interpolated': 'air_quality_hcho_interpolated.csv',
        'Aerosol Index Interpolated': 'air_quality_aer_ai_interpolated.csv',
        'Population Data': 'population_density.csv'
    }
    
    print("ğŸ“Š DATA AVAILABILITY CHECK:")
    available_datasets = {}
    for name, filename in data_files.items():
        filepath = Path(f'data/{filename}')
        if filepath.exists():
            df = pd.read_csv(filepath)
            available_datasets[name] = df
            print(f"   âœ… {name}: {len(df):,} records")
        else:
            print(f"   âŒ {name}: Not found")
    
    if 'Combined Grid Data' in available_datasets:
        combined_df = available_datasets['Combined Grid Data']
        
        print(f"\nğŸ—ºï¸ SPATIAL GRID ANALYSIS:")
        unique_points = combined_df[['lat', 'lon']].drop_duplicates()
        unique_dates = combined_df['date'].nunique()
        
        print(f"   ğŸ“ Grid Points: {len(unique_points)} locations")
        print(f"   ğŸ“… Time Period: {unique_dates} days")
        print(f"   ğŸŒ Coverage Area:")
        print(f"      Latitude: {combined_df['lat'].min():.3f}Â°N to {combined_df['lat'].max():.3f}Â°N")
        print(f"      Longitude: {combined_df['lon'].min():.3f}Â°E to {combined_df['lon'].max():.3f}Â°E")
        
        # Analyze pollutant correlations
        pollutant_cols = [col for col in combined_df.columns if '_value' in col]
        if len(pollutant_cols) >= 2:
            print(f"\nğŸ”¬ POLLUTANT CORRELATION ANALYSIS:")
            latest_data = combined_df[combined_df['date'] == combined_df['date'].max()]
            corr_matrix = latest_data[pollutant_cols].corr()
            
            print("   Strong Correlations (|r| > 0.5):")
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) > 0.5:
                        pol1 = corr_matrix.columns[i].replace('_value', '')
                        pol2 = corr_matrix.columns[j].replace('_value', '')
                        relation = "positive" if corr_val > 0 else "negative"
                        print(f"      {pol1} â†” {pol2}: {corr_val:.2f} ({relation})")
    
    if 'Composite AQI' in available_datasets:
        aqi_df = available_datasets['Composite AQI']
        
        print(f"\nğŸ­ COMPOSITE AIR QUALITY INDEX:")
        latest_aqi = aqi_df[aqi_df['date'] == aqi_df['date'].max()]
        
        print(f"   ğŸ“Š Average AQI Score: {latest_aqi['aqi_score'].mean():.1f}")
        print(f"   ğŸ“ˆ AQI Range: {latest_aqi['aqi_score'].min():.1f} - {latest_aqi['aqi_score'].max():.1f}")
        
        # AQI category distribution
        aqi_dist = latest_aqi['aqi_category'].value_counts()
        print(f"   ğŸ¯ Air Quality Distribution:")
        for category, count in aqi_dist.items():
            percentage = (count / len(latest_aqi)) * 100
            print(f"      {category}: {count} points ({percentage:.1f}%)")
        
        # Identify pollution hotspots
        worst_areas = latest_aqi.nlargest(5, 'aqi_score')
        print(f"   ğŸš¨ Top 5 Pollution Hotspots:")
        for i, (_, area) in enumerate(worst_areas.iterrows(), 1):
            print(f"      {i}. AQI {area['aqi_score']:.1f} at {area['lat']:.3f}Â°N, {area['lon']:.3f}Â°E ({area['aqi_category']})")
    
    # Population exposure analysis
    if 'Population Data' in available_datasets:
        pop_df = available_datasets['Population Data']
        
        print(f"\nğŸ‘¥ POPULATION EXPOSURE ANALYSIS:")
        print(f"   ğŸ“Š Population Points: {len(pop_df):,}")
        print(f"   ğŸ˜ï¸ Total Population: ~{pop_df['population_density'].sum()/1000:.0f}K people")
        
        high_density_areas = pop_df[pop_df['population_density'] > 1000]
        print(f"   ğŸ™ï¸ High Density Areas: {len(high_density_areas)} locations (>1000 people/kmÂ²)")
    
    print(f"\nğŸ¯ SYSTEM CAPABILITIES:")
    capabilities = [
        "âœ… 6 different air pollutants (NOâ‚‚, SOâ‚‚, CO, Oâ‚ƒ, HCHO, Aerosols)",
        "âœ… Consistent 40Ã—40 spatial grid (1600 measurement points)",
        "âœ… Smooth spatial interpolation for realistic pollution surfaces", 
        "âœ… Composite Air Quality Index combining all pollutants",
        "âœ… WHO health guideline comparisons",
        "âœ… Pollution source correlation analysis",
        "âœ… Population exposure risk assessment",
        "âœ… Interactive heatmap visualization", 
        "âœ… Hotspot identification and ranking",
        "âœ… Ready for real Sentinel-5P satellite integration"
    ]
    
    for capability in capabilities:
        print(f"   {capability}")
    
    print(f"\nğŸ“± WEB INTERFACE:")
    print(f"   ğŸŒ Streamlit App: http://localhost:8501")
    print(f"   ğŸ“Š Navigate to: 'ğŸ’¨ Air Quality' page")
    print(f"   ğŸ”„ Try dropdown: 'ğŸŒ Composite Air Quality Index'")
    print(f"   ğŸ—ºï¸ Toggle population overlay to see exposure analysis")
    
    print(f"\n" + "=" * 55)
    print("ğŸ† READY FOR NASA SPACE APPS CHALLENGE JUDGES!")
    print("=" * 55)

if __name__ == "__main__":
    analyze_air_quality_system()